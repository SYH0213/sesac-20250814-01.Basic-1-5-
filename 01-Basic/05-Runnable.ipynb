{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .env íŒŒì¼ì„ ì½ì–´ì„œ í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# í† í° ì •ë³´ë¡œë“œ\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith ì¶”ì ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "[í”„ë¡œì íŠ¸ëª…]\n",
      "sesac-CH1\n"
     ]
    }
   ],
   "source": [
    "# LangSmith ì¶”ì ì„ ì„¤ì •í•©ë‹ˆë‹¤. https://smith.langchain.com\n",
    "# !pip install -qU langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ì´ë¦„ì„ ì…ë ¥í•©ë‹ˆë‹¤.\n",
    "logging.langsmith(\"sesac-CH1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë°ì´í„°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì „ë‹¬í•˜ëŠ” ë°©ë²•\n",
    "\n",
    "- `RunnablePassthrough` ëŠ” ì…ë ¥ì„ ë³€ê²½í•˜ì§€ ì•Šê±°ë‚˜ ì¶”ê°€ í‚¤ë¥¼ ë”í•˜ì—¬ ì „ë‹¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
    "- `RunnablePassthrough()` ê°€ ë‹¨ë…ìœ¼ë¡œ í˜¸ì¶œë˜ë©´, ë‹¨ìˆœíˆ ì…ë ¥ì„ ë°›ì•„ ê·¸ëŒ€ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.\n",
    "- `RunnablePassthrough.assign(...)` ë°©ì‹ìœ¼ë¡œ í˜¸ì¶œë˜ë©´, ì…ë ¥ì„ ë°›ì•„ assign í•¨ìˆ˜ì— ì „ë‹¬ëœ ì¶”ê°€ ì¸ìˆ˜ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RunnablePassthrough\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# prompt ì™€ llm ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "prompt = PromptTemplate.from_template(\"{num} ì˜ ì†Œì¸ìˆ˜ëŠ”?\")\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# chain ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chain ì„ `invoke()` í•˜ì—¬ ì‹¤í–‰í•  ë•ŒëŠ” ì…ë ¥ ë°ì´í„°ì˜ íƒ€ì…ì´ ë”•ì…”ë„ˆë¦¬ì—¬ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='2, 3, 11', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 16, 'total_tokens': 23, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-C4N78xIKP0QAa0nUTPu188ElnzFez', 'finish_reason': 'stop', 'logprobs': None}, id='run-dab7a6c2-3c98-418f-83f7-60bf17cd2f7f-0', usage_metadata={'input_tokens': 16, 'output_tokens': 7, 'total_tokens': 23, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.\n",
    "chain.invoke({\"num\": 66})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í•˜ì§€ë§Œ, langchain ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—…ë°ì´íŠ¸ ë˜ë©´ì„œ 1ê°œì˜ ë³€ìˆ˜ë§Œ í…œí”Œë¦¿ì— í¬í•¨í•˜ê³  ìˆë‹¤ë©´, ê°’ë§Œ ì „ë‹¬í•˜ëŠ” ê²ƒë„ ê°€ëŠ¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='15ì˜ ì†Œì¸ìˆ˜ëŠ” 3ê³¼ 5ì…ë‹ˆë‹¤.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 16, 'total_tokens': 30, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-C4N7LIT1W81uHuZSeXZV3mxAyGepm', 'finish_reason': 'stop', 'logprobs': None}, id='run-8faa071b-8ad1-4b81-a52f-8125140755ff-0', usage_metadata={'input_tokens': 16, 'output_tokens': 14, 'total_tokens': 30, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.\n",
    "chain.invoke(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì•„ë˜ëŠ” `RunnablePassthrough` ë¥¼ ì‚¬ìš©í•œ ì˜ˆì œì…ë‹ˆë‹¤.\n",
    "\n",
    "`RunnablePassthrough` ëŠ” `runnable` ê°ì²´ì´ë©°, `runnable` ê°ì²´ëŠ” `invoke()` ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ë³„ë„ ì‹¤í–‰ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num': 10}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# runnable\n",
    "RunnablePassthrough().invoke({\"num\": 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì•„ë˜ëŠ” `RunnablePassthrough` ë¡œ ì²´ì¸ì„ êµ¬ì„±í•˜ëŠ” ì˜ˆì œì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='10ì˜ ì†Œì¸ìˆ˜ëŠ” 2ì™€ 5ì´ë‹¤.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 16, 'total_tokens': 31, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-C4N7WBXexNifN6jGMXbdPMOzpVFK4', 'finish_reason': 'stop', 'logprobs': None}, id='run-a193c396-f359-4206-afe0-a7e3dcce6433-0', usage_metadata={'input_tokens': 16, 'output_tokens': 15, 'total_tokens': 31, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable_chain = {\"num\": RunnablePassthrough()} | prompt | ChatOpenAI()\n",
    "\n",
    "# dict ê°’ì´ RunnablePassthrough() ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
    "runnable_chain.invoke(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë‹¤ìŒì€ `RunnablePassthrough.assign()` ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš°ì™€ ë¹„êµí•œ ê²°ê³¼ì…ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RunnablePassthrough().invoke({\"num\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RunnablePassthrough.assign()`\n",
    "\n",
    "- ì…ë ¥ ê°’ìœ¼ë¡œ ë“¤ì–´ì˜¨ ê°’ì˜ key/value ìŒê³¼ ìƒˆë¡­ê²Œ í• ë‹¹ëœ key/value ìŒì„ í•©ì¹©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num': 1, 'new_num': 3}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì…ë ¥ í‚¤: num, í• ë‹¹(assign) í‚¤: new_num\n",
    "(RunnablePassthrough.assign(new_num=lambda x: x[\"num\"] * 3)).invoke({\"num\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RunnableParallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì—¬ëŸ¬ Runnable ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë³‘ë ¬ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'passed': {'num': 1}, 'extra': {'num': 1, 'mult': 3}, 'modified': 2}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "# RunnableParallel ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì´ ì¸ìŠ¤í„´ìŠ¤ëŠ” ì—¬ëŸ¬ Runnable ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë³‘ë ¬ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "runnable = RunnableParallel(\n",
    "    # RunnablePassthrough ì¸ìŠ¤í„´ìŠ¤ë¥¼ 'passed' í‚¤ì›Œë“œ ì¸ìë¡œ ì „ë‹¬í•©ë‹ˆë‹¤. ì´ëŠ” ì…ë ¥ëœ ë°ì´í„°ë¥¼ ê·¸ëŒ€ë¡œ í†µê³¼ì‹œí‚¤ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
    "    passed=RunnablePassthrough(),\n",
    "    # 'extra' í‚¤ì›Œë“œ ì¸ìë¡œ RunnablePassthrough.assignì„ ì‚¬ìš©í•˜ì—¬, 'mult' ëŒë‹¤ í•¨ìˆ˜ë¥¼ í• ë‹¹í•©ë‹ˆë‹¤. ì´ í•¨ìˆ˜ëŠ” ì…ë ¥ëœ ë”•ì…”ë„ˆë¦¬ì˜ 'num' í‚¤ì— í•´ë‹¹í•˜ëŠ” ê°’ì„ 3ë°°ë¡œ ì¦ê°€ì‹œí‚µë‹ˆë‹¤.\n",
    "    extra=RunnablePassthrough.assign(mult=lambda x: x[\"num\"] * 3),\n",
    "    # 'modified' í‚¤ì›Œë“œ ì¸ìë¡œ ëŒë‹¤ í•¨ìˆ˜ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤. ì´ í•¨ìˆ˜ëŠ” ì…ë ¥ëœ ë”•ì…”ë„ˆë¦¬ì˜ 'num' í‚¤ì— í•´ë‹¹í•˜ëŠ” ê°’ì— 1ì„ ë”í•©ë‹ˆë‹¤.\n",
    "    modified=lambda x: x[\"num\"] + 1,\n",
    ")\n",
    "\n",
    "# runnable ì¸ìŠ¤í„´ìŠ¤ì— {'num': 1} ë”•ì…”ë„ˆë¦¬ë¥¼ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬í•˜ì—¬ invoke ë©”ì†Œë“œë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.\n",
    "runnable.invoke({\"num\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chain ë„ RunnableParallel ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain1 = (\n",
    "    {\"country\": RunnablePassthrough()}\n",
    "    | PromptTemplate.from_template(\"{country} ì˜ ìˆ˜ë„ëŠ”?\")\n",
    "    | ChatOpenAI()\n",
    ")\n",
    "chain2 = (\n",
    "    {\"country\": RunnablePassthrough()}\n",
    "    | PromptTemplate.from_template(\"{country} ì˜ ë©´ì ì€?\")\n",
    "    | ChatOpenAI()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'capital': AIMessage(content='ì„œìš¸íŠ¹ë³„ì‹œì…ë‹ˆë‹¤.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 19, 'total_tokens': 29, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-C4N8v0R0XYOBI2dmYlU3UTGCZbCbC', 'finish_reason': 'stop', 'logprobs': None}, id='run-6b8ce644-715f-4ba1-b64c-e04547f36080-0', usage_metadata={'input_tokens': 19, 'output_tokens': 10, 'total_tokens': 29, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " 'area': AIMessage(content='ëŒ€í•œë¯¼êµ­ì˜ ì´ ë©´ì ì€ ì•½ 100,363 kmÂ² ì…ë‹ˆë‹¤.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 20, 'total_tokens': 45, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-C4N8wWH6kEPpbI0JzQXzpva6Ke5Co', 'finish_reason': 'stop', 'logprobs': None}, id='run-93a17117-601e-490e-a790-ba019ea8f0ac-0', usage_metadata={'input_tokens': 20, 'output_tokens': 25, 'total_tokens': 45, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_chain = RunnableParallel(capital=chain1, area=chain2)\n",
    "combined_chain.invoke(\"ëŒ€í•œë¯¼êµ­\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RunnableLambda\n",
    "\n",
    "RunnableLambda ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì •ì˜ í•¨ìˆ˜ë¥¼ ë§µí•‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aug-14'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def get_today(a):\n",
    "    # ì˜¤ëŠ˜ ë‚ ì§œë¥¼ ê°€ì ¸ì˜¤ê¸°\n",
    "    return datetime.today().strftime(\"%b-%d\")\n",
    "\n",
    "\n",
    "# ì˜¤ëŠ˜ ë‚ ì§œë¥¼ ì¶œë ¥\n",
    "get_today(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "# prompt ì™€ llm ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"{today} ê°€ ìƒì¼ì¸ ìœ ëª…ì¸ {n} ëª…ì„ ë‚˜ì—´í•˜ì„¸ìš”. ìƒë…„ì›”ì¼ì„ í‘œê¸°í•´ ì£¼ì„¸ìš”.\"\n",
    ")\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4.1-mini\")\n",
    "\n",
    "# chain ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "chain = (\n",
    "    {\"today\": RunnableLambda(get_today), \"n\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‹¤ìŒì€ 8ì›” 14ì¼ì´ ìƒì¼ì¸ ìœ ëª…ì¸ 10ëª…ê³¼ ê·¸ë“¤ì˜ ìƒë…„ì›”ì¼ì…ë‹ˆë‹¤:\n",
      "\n",
      "1. ìŠ¤í‹°ë¸Œ ë§ˆí‹´ (Steve Martin) - 1945ë…„ 8ì›” 14ì¼  \n",
      "2. ë§¤ê¸° ê·¸ë ˆì´ìŠ¤ (Maggie Grace) - 1983ë…„ 8ì›” 14ì¼  \n",
      "3. ìœŒë¦¬ì—„ í—ˆíŠ¸ (William Hurt) - 1950ë…„ 8ì›” 14ì¼  \n",
      "4. ìƒ¤ë¥¼ë¦¬ì¦ˆ í…Œë¡  (Charlize Theron) - 1975ë…„ 8ì›” 14ì¼  \n",
      "5. ë°ì´ë¹„ë“œ í¬ë¡œìŠ¤ (David Cross) - 1964ë…„ 8ì›” 14ì¼  \n",
      "6. í¬ë¦¬ìŠ¤í‹´ ë²¨ (Kristen Bell) - 1980ë…„ 8ì›” 14ì¼  \n",
      "7. ì œì„ìŠ¤ ìºë¨¸ëŸ° (James Cameron) - 1954ë…„ 8ì›” 14ì¼  \n",
      "8. ì œë‹ˆí¼ ëŸ¬ë¸Œ íœ´ì‡ (Jennifer Love Hewitt) - 1979ë…„ 8ì›” 14ì¼  \n",
      "9. ìƒ¤ë¡  ìŠ¤í†¤ (Sharon Stone) - 1958ë…„ 8ì›” 14ì¼  \n",
      "10. íƒ€ì´ìŠ¨ ê²Œì´ (Tyson Gay) - 1982ë…„ 8ì›” 14ì¼  \n",
      "\n",
      "í•„ìš”í•˜ì‹œë©´ ë” ë§ì€ ì •ë³´ë¥¼ ì œê³µí•´ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ì¶œë ¥\n",
    "print(chain.invoke(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`itemgetter` ë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • í‚¤ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# ë¬¸ì¥ì˜ ê¸¸ì´ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
    "def length_function(text):\n",
    "    return len(text)\n",
    "\n",
    "\n",
    "# ë‘ ë¬¸ì¥ì˜ ê¸¸ì´ë¥¼ ê³±í•œ ê°’ì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
    "def _multiple_length_function(text1, text2):\n",
    "    return len(text1) * len(text2)\n",
    "\n",
    "\n",
    "# _multiple_length_function í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‘ ë¬¸ì¥ì˜ ê¸¸ì´ë¥¼ ê³±í•œ ê°’ì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
    "def multiple_length_function(_dict):\n",
    "    return _multiple_length_function(_dict[\"text1\"], _dict[\"text2\"])\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"{a} + {b} ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\")\n",
    "model = ChatOpenAI()\n",
    "\n",
    "chain1 = prompt | model\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"a\": itemgetter(\"word1\") | RunnableLambda(length_function),\n",
    "        \"b\": {\"text1\": itemgetter(\"word1\"), \"text2\": itemgetter(\"word2\")}\n",
    "        | RunnableLambda(multiple_length_function),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='5 + 25ëŠ” 30ì…ë‹ˆë‹¤.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 22, 'total_tokens': 31, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-C4NAN9l4VjI0kqd5gxfg8QLIts5bI', 'finish_reason': 'stop', 'logprobs': None}, id='run-af1f36e5-f9fd-4066-af95-c767b5dfc27c-0', usage_metadata={'input_tokens': 22, 'output_tokens': 9, 'total_tokens': 31, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"word1\": \"hello\", \"word2\": \"world\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒ ëœë¤ ì„ íƒëœ ë‚˜ë¼: í–„ë²„ê±°\n",
      "\n",
      "--- ìµœì¢… ê²°ê³¼ ---\n",
      "{\n",
      "  \"food_ingredient\": \"í–„ë²„ê±°ëŠ” ë‹¤ì–‘í•œ ì¬ë£Œë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. ê¸°ë³¸ì ì¸ ì¬ë£ŒëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\\n\\n1. **ë²ˆ(Bun)**: í–„ë²„ê±°ì˜ ë¹µ ë¶€ë¶„ìœ¼ë¡œ, ì¼ë°˜ì ìœ¼ë¡œ ìœ„ì™€ ì•„ë˜ì— ê°ê° í•œ ê°œì”© ì¡´ì¬í•©ë‹ˆë‹¤.\\n2. **íŒ¨í‹°(Patty)**: ê³ ê¸° ë˜ëŠ” ì‹ë¬¼ ê¸°ë°˜ ì¬ë£Œë¡œ ë§Œë“¤ì–´ì§„ ë¶€ë¶„ì…ë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ì†Œê³ ê¸° íŒ¨í‹°ê°€ ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ì§€ë§Œ, ë‹­ê³ ê¸°, ë¼ì§€ê³ ê¸°, ìƒì„ , í˜¹ì€ ì±„ì‹ìš© ë²„ê±° ë“± ë‹¤ì–‘í•œ ì˜µì…˜ì´ ìˆìŠµë‹ˆë‹¤.\\n3. **ì¹˜ì¦ˆ(Cheese)**: ë³´í†µ í–„ë²„ê±° ìœ„ì— ì–¹ì–´ ë…¹ì¸ ì¹˜ì¦ˆê°€ ì‚¬ìš©ë©ë‹ˆë‹¤. ì²´ë‹¤, ëª¨ì§œë ë¼, ìŠ¤ìœ„ìŠ¤ ì¹˜ì¦ˆ ë“±ì´ ì¼ë°˜ì ì…ë‹ˆë‹¤.\\n4. **ì•¼ì±„(Vegetables)**: ìƒì¶”, í† ë§ˆí† , ì–‘íŒŒ, í”¼í´ ë“± ë‹¤ì–‘í•œ ì‹ ì„ í•œ ì•¼ì±„ê°€ ì¶”ê°€ë©ë‹ˆë‹¤.\\n5. **ì†ŒìŠ¤(Sauces)**: ë§ˆìš”ë„¤ì¦ˆ, ì¼€ì²©, ë¨¸ìŠ¤íƒ€ë“œ, ë°”ë¹„í ì†ŒìŠ¤ ë“± ë‹¤ì–‘í•œ ì†ŒìŠ¤ê°€ ì‚¬ìš©ë˜ì–´ í’ë¯¸ë¥¼ ë”í•©ë‹ˆë‹¤.\\n\\nì´ ì™¸ì—ë„ ë² ì´ì»¨, ì•„ë³´ì¹´ë„, ì¹ ë¦¬, ë‹¤ì–‘í•œ í–¥ì‹ ë£Œì™€ í—ˆë¸Œ ë“±ì„ ì¶”ê°€í•˜ì—¬ í–„ë²„ê±°ë¥¼ ë”ìš± í’ë¶€í•˜ê²Œ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\",\n",
      "  \"food_cooking\": \"í–„ë²„ê±°ë¥¼ ë§Œë“œëŠ” ê¸°ë³¸ì ì¸ ìš”ë¦¬ë²•ì„ ì†Œê°œí•´ë“œë¦´ê²Œìš”! ê°„ë‹¨í•œ ì¬ë£Œì™€ ë‹¨ê³„ë¥¼ í†µí•´ ë§›ìˆëŠ” í–„ë²„ê±°ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n### ì¬ë£Œ\\n- ë‹¤ì§„ ì†Œê³ ê¸° (ì‡ ê³ ê¸°) 500g\\n- í–„ë²„ê±° ë²ˆ (ë¹µ) 4ê°œ\\n- ì†Œê¸ˆ, í›„ì¶” (ê¸°í˜¸ì— ë”°ë¼)\\n- ì¹˜ì¦ˆ (ì²´ë‹¤ ì¹˜ì¦ˆ ë“±) 4ì¥ (ì„ íƒ ì‚¬í•­)\\n- í† ë§ˆí†  1ê°œ (ìŠ¬ë¼ì´ìŠ¤)\\n- ì–‘ìƒì¶” ëª‡ ì¥\\n- ì–‘íŒŒ (ìŠ¬ë¼ì´ìŠ¤, ì„ íƒ ì‚¬í•­)\\n- ë§ˆìš”ë„¤ì¦ˆ, ì¼€ì²©, ë¨¸ìŠ¤íƒ€ë“œ (ì„ íƒ ì‚¬í•­)\\n\\n### ìš”ë¦¬ ë°©ë²•\\n\\n1. **íŒ¨í‹° ë§Œë“¤ê¸°**:\\n   - ë‹¤ì§„ ì†Œê³ ê¸°ë¥¼ í° ê·¸ë¦‡ì— ë‹´ê³  ì†Œê¸ˆê³¼ í›„ì¶”ë¡œ ê°„ì„ í•©ë‹ˆë‹¤.\\n   - ì†ìœ¼ë¡œ ê³ ê¸°ë¥¼ ì ë‹¹í•œ í¬ê¸°ë¡œ ë‚˜ëˆ„ì–´ì„œ (ì•½ 125g ì •ë„) ë‘¥ê¸€ê²Œ ëª¨ì–‘ì„ ë§Œë“­ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ, ê°€ìš´ë°ë¥¼ ì•½ê°„ ëˆŒëŸ¬ì„œ ë‘ê»˜ê°€ ê³ ë¥´ê²Œ ë˜ë„ë¡ í•©ë‹ˆë‹¤.\\n\\n2. **êµ½ê¸°**:\\n   - íŒ¬ì´ë‚˜ ê·¸ë¦´ì„ ì¤‘ê°•ë¶ˆë¡œ ì˜ˆì—´í•©ë‹ˆë‹¤. íŒ¬ì— ì¡°ê¸ˆì˜ ê¸°ë¦„ì„ ë‘˜ëŸ¬ì¤ë‹ˆë‹¤.\\n   - íŒ¨í‹°ë¥¼ íŒ¬ì´ë‚˜ ê·¸ë¦´ì— ì˜¬ë¦¬ê³  ì•½ 3~4ë¶„ ì •ë„ êµ¬ìš´ í›„, ë’¤ì§‘ì–´ì„œ ë°˜ëŒ€ìª½ë„ ì•½ 3ë¶„ ì •ë„ ë” êµ½ìŠµë‹ˆë‹¤. (ê³ ê¸°ì˜ ë‘ê»˜ì— ë”°ë¼ ì¡°ë¦¬ ì‹œê°„ì€ ì¡°ì ˆí•´ì£¼ì„¸ìš”.)\\n   - ì¹˜ì¦ˆë¥¼ ì¶”ê°€í•˜ê³  ì‹¶ë‹¤ë©´, íŒ¨í‹° ìœ„ì— ì¹˜ì¦ˆë¥¼ ì–¹ê³  1ë¶„ ì •ë„ ë” êµ½ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë©´ ì¹˜ì¦ˆê°€ ë…¹ì•„ë“¤ê²Œ ë©ë‹ˆë‹¤.\\n\\n3. **ë¹µ êµ½ê¸°**:\\n   - í—ˆë¸Œ í¬ëŸ¬ìŠ¤íŠ¸ë¥¼ ì›í•˜ì‹œë©´ ë²ˆì„ ë°˜ìœ¼ë¡œ ì˜ë¼ì„œ íŒ¬ì— ì•½ê°„ êµ¬ì›Œì¤ë‹ˆë‹¤. (ì›í•˜ëŠ” ê²½ìš°)\\n\\n4. **í–„ë²„ê±° ì¡°ë¦½**:\\n   - ë²ˆì˜ ì•„ë˜ìª½ì— ë§ˆìš”ë„¤ì¦ˆ, ì¼€ì²©, ë¨¸ìŠ¤íƒ€ë“œ ë“±ì„ ë°”ë¥´ê³ , ê·¸ ìœ„ì— êµ¬ìš´ íŒ¨í‹°ë¥¼ ì˜¬ë¦½ë‹ˆë‹¤.\\n   - ìŠ¬ë¼ì´ìŠ¤í•œ í† ë§ˆí† , ì–‘ìƒì¶”, ì–‘íŒŒë¥¼ ìˆœì„œëŒ€ë¡œ ìŒ“ìŠµë‹ˆë‹¤.\\n   - ë²ˆì˜ ìœ—ë¶€ë¶„ì„ ë®ìŠµë‹ˆë‹¤.\\n\\n5. **ì„œë¹™**:\\n   - ì™„ì„±ëœ í–„ë²„ê±°ë¥¼ ì ‘ì‹œì— ë‹´ê³ , ê°ìíŠ€ê¹€ì´ë‚˜ ë‹¤ë¥¸ ì‚¬ì´ë“œì™€ í•¨ê»˜ ì¦ê¸°ì„¸ìš”!\\n\\ní–„ë²„ê±°ëŠ” ì·¨í–¥ì— ë”°ë¼ ë‹¤ì–‘í•œ ì¬ë£Œë¥¼ ì¶”ê°€í•˜ê±°ë‚˜ ë³€ê²½í•  ìˆ˜ ìˆìœ¼ë‹ˆ, ë‚˜ë§Œì˜ íŠ¹ë³„í•œ ë ˆì‹œí”¼ë¥¼ ë§Œë“¤ì–´ë³´ì„¸ìš”! ë§›ìˆê²Œ ë“œì„¸ìš”!\",\n",
      "  \"food_restaurant\": \"ì„œìš¸ ê°•ë™êµ¬ì—ëŠ” ë‹¤ì–‘í•œ í–„ë²„ê±° ë§›ì§‘ì´ ìˆìŠµë‹ˆë‹¤. ê·¸ ì¤‘ì—ì„œ ëª‡ ê³³ì„ ì¶”ì²œí•´ ë“œë¦´ê²Œìš”.\\n\\n1. **ë²„ê±°ë„ˆìŠ¤**: ì‹ ì„ í•œ ì¬ë£Œë¡œ ë§Œë“  ìˆ˜ì œë²„ê±°ê°€ ìœ ëª…í•œ ê³³ì…ë‹ˆë‹¤. ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ ë²„ê±°ì™€ ì‚¬ì´ë“œ ë©”ë‰´ë¥¼ ì¦ê¸¸ ìˆ˜ ìˆìœ¼ë©°, ë¶„ìœ„ê¸°ë„ ì•„ëŠ‘í•©ë‹ˆë‹¤.\\n\\n2. **í•«í˜í¼ë²„ê±°**: ë§¤ì½¤í•œ ë§›ì´ íŠ¹ì§•ì¸ í–„ë²„ê±°ë¥¼ ì œê³µí•˜ëŠ” ê³³ì…ë‹ˆë‹¤. ë…íŠ¹í•œ ì†ŒìŠ¤ì™€ ì‹ ì„ í•œ ì¬ë£Œë¡œ ë§Œë“  í–„ë²„ê±°ê°€ ì¸ê¸°ì…ë‹ˆë‹¤.\\n\\n3. **ë§˜ìŠ¤í„°ì¹˜ ì‹¸ì´ìˆœì‚´**: ë²„ê±° ì „ë¬¸ì ì€ ì•„ë‹ˆì§€ë§Œ, ì¹˜í‚¨ ë²„ê±°ê°€ íŠ¹íˆ ë§›ìˆìŠµë‹ˆë‹¤. ë°”ì‚­í•œ ì¹˜í‚¨ê³¼ ì‹ ì„ í•œ ì±„ì†Œê°€ ì¡°í™”ë¥¼ ì´ë£¨ì–´ ë§ì€ ì‚¬ëŒë“¤ì—ê²Œ ì‚¬ë‘ë°›ê³  ìˆìŠµë‹ˆë‹¤.\\n\\n4. **í•˜ë“œë¡ ì¹´í˜**: ê¸€ë¡œë²Œ ì²´ì¸ìœ¼ë¡œ ìœ ëª…í•œ ê³³ì´ì§€ë§Œ, í–„ë²„ê±° ë©”ë‰´ê°€ ë§¤ìš° ì˜ ë§Œë“¤ì–´ì ¸ ìˆìŠµë‹ˆë‹¤. íŠ¹ë³„í•œ ë¼ì¸ì—…ì˜ ë²„ê±°ì™€ ìŒë£Œë¥¼ í•¨ê»˜ ì¦ê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n5. **ë¸Œë£¨ì–´ë¦¬ ê°•ë™**: ìˆ˜ì œ ë§¥ì£¼ì™€ í•¨ê»˜ ì¦ê¸¸ ìˆ˜ ìˆëŠ” ìˆ˜ì œë²„ê±° ì „ë¬¸ì ì…ë‹ˆë‹¤. ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ í–„ë²„ê±°ì™€ í•¨ê»˜ ìˆ˜ì œ ë§¥ì£¼ë¥¼ ë§›ë³¼ ìˆ˜ ìˆì–´ ë§¥ì£¼ ì• í˜¸ê°€ë“¤ì—ê²Œ ì¸ê¸°ê°€ ë§ìŠµë‹ˆë‹¤.\\n\\në°©ë¬¸í•˜ì‹œê¸° ì „ì— ì˜ì—…ì‹œê°„ê³¼ ë©”ë‰´ë¥¼ í™•ì¸í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ì¦ê±°ìš´ ì‹ì‚¬ ë˜ì„¸ìš”!\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import (\n",
    "    RunnablePassthrough,\n",
    "    RunnableParallel,\n",
    "    RunnableLambda,\n",
    ")\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import json\n",
    "import random  # random ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€\n",
    "\n",
    "# --- (ì´ì „ ì½”ë“œì™€ ë™ì¼í•œ ë¶€ë¶„) ---\n",
    "\n",
    "# ëª¨ë¸ ì´ˆê¸°í™” (gpt-4o-miniëŠ” ë¹ ë¥´ê³  ì €ë ´í•˜ì—¬ í…ŒìŠ¤íŠ¸ì— ìš©ì´í•©ë‹ˆë‹¤)\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 1. ìš”ë¦¬ì˜ ì¬ë£Œ\n",
    "prompt1 = ChatPromptTemplate.from_template(\n",
    "    \"{food}ì˜ ì¬ë£Œë¥¼ ì•Œë ¤ì¤˜\"\n",
    ")\n",
    "chain1 = {\"food\": RunnablePassthrough()} | prompt1 | model | StrOutputParser()\n",
    "\n",
    "# 2. ìš”ë¦¬ë²•\n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"{food}ì˜ ìš”ë¦¬ë²•ì„ ì•Œë ¤ì¤˜\"\n",
    ")\n",
    "chain2 = {\"food\": RunnablePassthrough()} | prompt2 | model | StrOutputParser()\n",
    "\n",
    "# 3. ë§›ì§‘ ì¶”ì²œ\n",
    "prompt3 = ChatPromptTemplate.from_template(\n",
    "    \"ì„œìš¸ ê°•ë™êµ¬ì—ì„œ {food}ì˜ ë§›ì§‘ì„ ì¶”ì²œí•´ì¤˜\"\n",
    ")\n",
    "chain3 = {\"food\": RunnablePassthrough()} | prompt3 | model | StrOutputParser()\n",
    "\n",
    "# 4. RunnableParallelì„ ì‚¬ìš©í•˜ì—¬ ì„¸ê°œì˜ ì²´ì¸ í†µí•©\n",
    "combined_chain = RunnableParallel(food_ingredient=chain1, food_cooking=chain2, food_restaurant=chain3)\n",
    "\n",
    "\n",
    "# 5. ìš”ë¦¬ì˜ ì´ë¦„ì„ ëœë¤ìœ¼ë¡œ ì„ íƒí•˜ëŠ” í•¨ìˆ˜ ì •ì˜\n",
    "def choice_country(_):  # LangChain ì²´ì¸ê³¼ ì—°ê²°í•˜ê¸° ìœ„í•´ ì…ë ¥ ì¸ìë¥¼ ë°›ë„ë¡ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"ì£¼ì–´ì§„ ë¦¬ìŠ¤íŠ¸ì—ì„œ êµ­ê°€ë¥¼ í•˜ë‚˜ ëœë¤ìœ¼ë¡œ ì„ íƒí•©ë‹ˆë‹¤.\"\"\"\n",
    "    foods = [\"ìŠ¤íŒŒê²Œí‹°\", \"í–„ë²„ê±°\", \"í”¼ì\", \"ì¹´ë ˆ\", \"ê¹€ë°¥\"]\n",
    "    select_food = random.choice(foods)  # ëœë¤ìœ¼ë¡œ ìŒì‹ ì„ íƒ\n",
    "\n",
    "    # ì–´ë–¤ ë‚˜ë¼ê°€ ì„ íƒë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ ì¶œë ¥\n",
    "    print(f\"ëœë¤ ì„ íƒëœ ìš”ë¦¬: {select_food}\")\n",
    "\n",
    "    return select_food\n",
    "\n",
    "\n",
    "# 5. RunnableLambdaë¡œ í•¨ìˆ˜ë¥¼ ì²´ì¸ì— í†µí•©í•˜ê³  ìµœì¢… ì²´ì¸ ì™„ì„±\n",
    "# [ë‚˜ë¼ ì„ íƒ í•¨ìˆ˜] -> [ê¸°ì¡´ì˜ ë³‘ë ¬ ì²´ì¸] ìˆœì„œë¡œ ì‹¤í–‰\n",
    "final_chain = RunnableLambda(choice_country) | combined_chain\n",
    "\n",
    "# 6. ìµœì¢… ì²´ì¸ ì‹¤í–‰\n",
    "# ì…ë ¥ê°’ì´ í•„ìš” ì—†ìœ¼ë¯€ë¡œ Noneì„ ì „ë‹¬ (ë˜ëŠ” ë¹„ì›Œë‘ )\n",
    "result = final_chain.invoke(None)\n",
    "\n",
    "# 7. ê²°ê³¼ ì¶œë ¥\n",
    "print(\"\\n--- ìµœì¢… ê²°ê³¼ ---\")\n",
    "print(json.dumps(result, indent=2, ensure_ascii=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-yQIPbTyB-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
