# ì˜¤ëŠ˜ì˜ ê°œë… ë³µìŠµ (LangChain & ë¹„ë™ê¸°) ğŸš€

> **ëª©í‘œ:** GitHubì— ì˜¬ë¦´ ìˆ˜ ìˆë„ë¡, ì˜¤ëŠ˜ ë‹¤ë£¬ í•µì‹¬ ê°œë…ì„ *ê°„ë‹¨ ìš”ì•½ + ì˜ˆì‹œ ì½”ë“œ*ë¡œ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.  
> í‚¤ì›Œë“œ: **LangSmith, Runnable, invoke/stream/batch/await, RunnableParallel, ë™ì‹œì„± vs ë³‘ë ¬ì„±**

---

## TL;DR
- **LangSmith**: LLM ì•±ì˜ *ë¡œê¹…/íŠ¸ë ˆì´ì‹±/í‰ê°€* í”Œë«í¼
- **Runnable(LCEL)**: LangChainì˜ í‘œì¤€ ì‹¤í–‰ ì¸í„°í˜ì´ìŠ¤ â€” `invoke / ainvoke / stream / astream / batch / abatch`
- **invoke vs stream vs batch**: **ë‹¨ê±´** / **ìŠ¤íŠ¸ë¦¬ë°** / **ë‹¤ê±´(ë¬¶ìŒ)** ì²˜ë¦¬
- **await**: ë¹„ë™ê¸° í•¨ìˆ˜ì˜ ê²°ê³¼ë¥¼ *ê¸°ë‹¤ë¦¬ëŠ”* í‚¤ì›Œë“œ(íŒŒì´ì¬ `asyncio`)
- **RunnableParallel**: ì—¬ëŸ¬ Runnableì„ **ë™ì‹œì—(ë™ì‹œì„±)** ì‹¤í–‰í•´ *ë§µ*ìœ¼ë¡œ ê²°ê³¼ ë°˜í™˜
- **ë™ì‹œì„± vs ë³‘ë ¬ì„±**: *ê²¹ì³ ì²˜ë¦¬* vs *ì§„ì§œ ë™ì‹œì— ê³„ì‚°*

---

## 1) LangSmith í•œëˆˆì— ë³´ê¸°
LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ í’ˆì§ˆì„ ë†’ì´ê¸° ìœ„í•œ **íŠ¸ë ˆì´ì‹±/ë””ë²„ê¹…/í‰ê°€** ë„êµ¬.
- **Tracing**: í”„ë¡¬í”„íŠ¸/ì‘ë‹µ/í† í°/ì§€ì—°ì‹œê°„ ë“± ì‹¤í–‰ ê²½ë¡œ ê¸°ë¡
- **Datasets & Evaluations**: ë°ì´í„°ì…‹ ê¸°ë°˜ ìë™ í‰ê°€(ì •í™•ë„/í¬ë§·/ë…ì„± ë“±)
- **Compare & Iterate**: í”„ë¡¬í”„íŠ¸/ëª¨ë¸ ë³€ê²½ì— ë”°ë¥¸ ì„±ëŠ¥ ë¹„êµ

> ì‹œì‘ 3ìš”ì†Œ: (1) **Dataset** (ì…ë ¥/ì •ë‹µ), (2) **Target**(í‰ê°€ ëŒ€ìƒ í•¨ìˆ˜/ì²´ì¸), (3) **Evaluators**(ì±„ì ê¸°)

---

## 2) Runnable & LCEL í•µì‹¬
**Runnable**ì€ LangChain ì»´í¬ë„ŒíŠ¸ë¥¼ *ì¼ê´€ëœ ë°©ë²•*ìœ¼ë¡œ ì‹¤í–‰í•˜ëŠ” ê³µí†µ ì¸í„°í˜ì´ìŠ¤ì…ë‹ˆë‹¤.  
LCEL(LangChain Expression Language) íŒŒì´í”„ êµ¬ì„±ì„ í†µí•´ **ë™ê¸°/ë¹„ë™ê¸°/ë°°ì¹˜/ìŠ¤íŠ¸ë¦¬ë°**ì„ *ìë™ ì§€ì›*í•©ë‹ˆë‹¤.

### ê³µí†µ ë©”ì„œë“œ ì¹˜íŠ¸ì‹œíŠ¸
| ë©”ì„œë“œ | ì„¤ëª… | ë°˜í™˜ |
|---|---|---|
| `invoke(input)` | ë‹¨ê±´ ë™ê¸° ì‹¤í–‰ | ê²°ê³¼(ëª¨ë¸ì€ ë³´í†µ `AIMessage`) |
| `ainvoke(input)` | ë‹¨ê±´ ë¹„ë™ê¸° ì‹¤í–‰ | `await` ê°€ëŠ¥í•œ ê²°ê³¼ |
| `stream(input)` | ë™ê¸° ìŠ¤íŠ¸ë¦¬ë°(ì²­í¬ ë‹¨ìœ„) | ì´í„°ë ˆì´í„° |
| `astream(input)` | ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¬ë° | async ì´í„°ë ˆì´í„° |
| `batch(list)` | ì—¬ëŸ¬ ì…ë ¥ **ë™ì‹œì—** ì²˜ë¦¬ | ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ |
| `abatch(list)` | ë¹„ë™ê¸° ë°°ì¹˜ | `await` ê°€ëŠ¥í•œ ë¦¬ìŠ¤íŠ¸ |

### ì˜ˆì‹œ: í”„ë¡¬í”„íŠ¸ â†’ ëª¨ë¸ â†’ ë¬¸ìì—´ íŒŒì„œ
```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

prompt = ChatPromptTemplate.from_template("í•œêµ­ ë¼ë©´ 5ì¢…ë¥˜ ì¶”ì²œí•´ì¤˜.")
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
chain = prompt | llm | StrOutputParser()

print(chain.invoke({}))             # ë™ê¸° ë‹¨ê±´
# await chain.ainvoke({})          # ë¹„ë™ê¸° ë‹¨ê±´
# for chunk in chain.stream({}):   # ìŠ¤íŠ¸ë¦¬ë°
#     print(chunk, end="")
```

---

## 3) stream / batch ê°„ë‹¨ ì´í•´
- **stream**: ëª¨ë¸ì˜ ì¶œë ¥ì„ **ì¡°ê°(í† í°/ë¬¸ì¥)** ë‹¨ìœ„ë¡œ *ë°”ë¡œë°”ë¡œ* ë°›ìŒ â†’ ì‹¤ì‹œê°„ UIì— ì í•©
- **batch**: ì…ë ¥ ë¦¬ìŠ¤íŠ¸ë¥¼ **ë¬¶ìŒ ì²˜ë¦¬** â†’ ë„¤íŠ¸ì›Œí¬ ëŒ€ê¸° ì‹œê°„ì„ ìˆ¨ê²¨ **ì²˜ë¦¬ëŸ‰â†‘**

```python
# batch ì˜ˆì‹œ
inputs = [{"q": f"item {i}"} for i in range(5)]
results = chain.batch(inputs, max_concurrency=5)
```

---

## 4) RunnableParallel (ì—¬ëŸ¬ ì‘ì—… ë™ì‹œ ì‹¤í–‰)
ì—¬ëŸ¬ Runnableì„ **ë™ì‹œì— ì‹¤í–‰**í•˜ê³ , ê²°ê³¼ë¥¼ *ë§µ(dict)* í˜•íƒœë¡œ ë°›ìŠµë‹ˆë‹¤.

```python
from langchain_core.runnables import RunnableParallel
from operator import itemgetter

qa = ChatPromptTemplate.from_template("Q: {q}\nA:")
summ = ChatPromptTemplate.from_template("Summarize: {text}")

parallel = RunnableParallel(
    answer = ({"q": itemgetter("q")} | qa | llm | StrOutputParser()),
    summary = ({"text": itemgetter("context")} | summ | llm | StrOutputParser()),
)

out = parallel.invoke({"q": "ë¼ë©´ ì—­ì‚¬", "context": "ë¼ë©´ì€ 1958ë…„ ì¼ë³¸ì—ì„œ..."})

# out -> {"answer": "...", "summary": "..."}
```

> ë‚´ë¶€ì ìœ¼ë¡œ ì…ë ¥ì„ ë™ì¼í•˜ê²Œ ë¸Œë¡œë“œìºìŠ¤íŠ¸í•˜ê³ , ê° ë¸Œëœì¹˜ë¥¼ **ë™ì‹œì„±**ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.

---

## 5) `await` (íŒŒì´ì¬ ë¹„ë™ê¸°)
íŒŒì´ì¬ `asyncio`ì—ì„œ **ë¹„ë™ê¸° í•¨ìˆ˜ì˜ ì™„ë£Œë¥¼ ê¸°ë‹¤ë¦¬ëŠ”** í‚¤ì›Œë“œ.

```python
import asyncio, aiohttp

async def fetch(url):
    async with aiohttp.ClientSession() as s:
        async with s.get(url) as r:
            return await r.text()

async def main():
    html = await fetch("https://example.com")
    print(len(html))

asyncio.run(main())
```

- **ë™ì‹œì„±(Concurrency)**: ì—¬ëŸ¬ I/O ì‘ì—…ì„ *ê²¹ì³* ì²˜ë¦¬(í•œ ì½”ì–´ì—ì„œë„ ê°€ëŠ¥)  
- **ë³‘ë ¬ì„±(Parallelism)**: ì—¬ëŸ¬ ì½”ì–´ê°€ *ì§„ì§œ ë™ì‹œì—* ê³„ì‚°(ì˜ˆ: `multiprocessing`)

---

## 6) ì‘ì€ íŒ¨í„´ ëª¨ìŒ
- **ì „/í›„ì²˜ë¦¬**: `RunnableLambda` + `RunnablePassthrough.assign(...)`
- **ë¶„ê¸° ì‹¤í–‰**: `RunnableBranch` (ì…ë ¥ ê°’/ìƒíƒœì— ë”°ë¼ ë‹¤ë¥¸ ì„œë¸Œì²´ì¸ ì„ íƒ)
- **Jupyter íŒ**: ìµœìƒìœ„ `await` ì§€ì› â†’ `await chain.ainvoke(...)`

---

## ì°¸ê³  ë§í¬
- LangSmith ê°œìš” & í‰ê°€: https://docs.smith.langchain.com/evaluation  
- Runnable ì¸í„°í˜ì´ìŠ¤: https://python.langchain.com/docs/concepts/runnables/  
- Streaming ê°€ì´ë“œ: https://python.langchain.com/docs/how_to/streaming/  
- RunnableParallel: https://python.langchain.com/docs/how_to/parallel/  
- Python `asyncio`: https://docs.python.org/3/library/asyncio.html  
- ë™ì‹œì„± vs ë³‘ë ¬ì„±(íŒŒì´ì¬ ë¬¸ì„œ/ê°€ì´ë“œ):  
  - https://docs.python.org/3/library/concurrency.html  
  - https://docs.python.org/3/library/multiprocessing.html